# -*- coding: utf-8 -*-
"""Slot6_Assignment

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NheIy37bbuNOJQctuZtZnGcXeFfxnHbM

###Portfólio Individual ML Classificação

1. Carregando Bibliotecas
"""

from pathlib import Path
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

"""2. Extração e Carregamento do Dataset"""

# Commented out IPython magic to ensure Python compatibility.
# %env KAGGLE_USERNAME=pmbraga12
# %env KAGGLE_KEY=c3de15e244a3ddf0ca14495d05aa7412

!kaggle datasets download -d ronitf/heart-disease-uci --unzip -p /content/heart-disease-uci
!ls /content/heart-disease-uci

DATA_PATH = Path("/content/heart-disease-uci")

heart_df = pd.read_csv(DATA_PATH / "heart.csv")

#Avaliando carregamento do dataset
print(heart_df.head(),heart_df.shape)

"""**DICIONÁRIO DATASET:**
- age: Idade (Anos)
- sex: Sexo (1 = Masc e 0 = Fem)
- cp: Nível de dor ( 1 a 4 )
- trestbps: Pressão sanguínea em Repouso
- chol: colesterol em mg/dl:
- fbs: Fasting Blood Sugar (Teste diabético) > 120 mg/dl
- restecg: Eletrocardiogramas em repouso (0,1 ou 2)
- thalach: Ritmo cardíaco
- exang: Exercício físico que gerou Angina
- oldpeak: Depressão de ST induzida por exercício em relação ao
repouso
- slope: Tipo de inclinação do segmento ST de pico do exercício
- ca: número de vasos sanguínios ressaltados (coloridos por
fluoroscopia)
- thal: Talassemia -> 3 = normal; 6 = fixed defect; 7 = reversable
defect

###3. EDA (Análise exploratória de dados)
"""

heart_df.head()

heart_df['restecg'].value_counts()

#Conseguimos aqui identificar que os tipos das variáveis FAZ SENTIDO e que NÃO temos valores nulos
heart_df.info()

heart_df.describe()

#Avaliando a correlação entre as variáveis
#Aqui percebemos que as principais variáveis com maior correlação com nossa variável target são: cp (nivel de dor) e thalach (ritmo cardíaco)
plt.figure(figsize=(12,10))
sns.heatmap(heart_df.corr(),annot=True,cmap="magma",fmt='.2f')

#Avaliando quantidade de valores únicos
for i in heart_df.columns:
    print(i,len(heart_df[i].unique()))

"""Aprofundando a análise para as variáveis com maior correlação: cp, exang"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
plt.figure(figsize = ((12, 6)))

plt.subplot(2, 2, 1)
sns.countplot(data=heart_df, x='cp',hue='target').set_title('Contagem dos níveis de dor')

plt.subplot(2, 2, 2)
sns.countplot(data=heart_df, x='exang',hue='target').set_title('Quantidade de casos oriundos de exercício físico');

"""PRE PROCESSING"""

from sklearn.model_selection import train_test_split # Import train_test_split function

X = heart_df.drop(['target'], axis=1) # Features
y = heart_df['target'] # Target variable

from sklearn.preprocessing import StandardScaler
X = StandardScaler().fit_transform(X)

#PCA
from sklearn import decomposition
pca = decomposition.PCA(n_components=2)
pca.fit(X)
X = pca.transform(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) #80% training and 20% test

"""Classification Tree"""

from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier
from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation

# Create Decision Tree classifer object
clf = DecisionTreeClassifier()

# Train Decision Tree Classifer
clf = clf.fit(X_train,y_train)

#Predict the response for test dataset
y_pred = clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

"""SVM """

from sklearn import svm
clf = svm.SVC(kernel='linear')
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

clf = svm.SVC(kernel='poly')
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

"""Redes Neurais"""

from sklearn.neural_network import MLPClassifier
clf_neural = MLPClassifier(random_state=42)
clf_neural.fit(X_train, y_train)
clf_neural_pred = clf_neural.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))